{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias que vamos a usar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import warnings\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo una funcion de pasar el archivo de json a csv para no repetir codigo\n",
    "def json_to_csv(archivo, archivo_final, coding):\n",
    "    itemsList = []\n",
    "# Abro un archivo y pongo el encoding que necesito\n",
    "    with open(archivo, \"r\", encoding= coding) as f:\n",
    "  # Recorro todo el json\n",
    "        for line in f.readlines():\n",
    "      # Todas las lineas del archivo las agrego a una lista\n",
    "            itemsList.append(ast.literal_eval(line))\n",
    "# Convierto la lista a un dataframe de pandas\n",
    "        dfItems = pd.DataFrame(itemsList)\n",
    "        #Devuelvo un csv para tener los archivos en un formato mas comodo y para optimizar los procesos de limpieza\n",
    "        return dfItems.to_csv(archivo_final, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uso la funcion que creamos antes\n",
    "json_to_csv(\"datasets/australian_user_reviews.json\", \"datasets/australian_user_reviews.csv\", \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uso la funcion que creamos antes\n",
    "json_to_csv(\"datasets/australian_users_items.json\", \"datasets/australian_user_items.csv\", \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el archivo de steam games\n",
    "dfSteamGames= pd.read_json(\"datasets/output_steam_games.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos el archivo de steam a csv para leerlo mas facil\n",
    "dfSteamGames.to_csv(\"datasets/output_steam_games.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos los csv y los asignamos a estas variables\n",
    "items = pd.read_csv(\"datasets/australian_user_items.csv\")\n",
    "reviews = pd.read_csv(\"datasets/australian_user_reviews.csv\")\n",
    "steam_games = pd.read_csv(\"datasets/output_steam_games.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo Steam Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liempiza de datos del archivo Steam Games\n",
    "#Seleccionamos las columnas que queremos eliminar que no sirven para el analisis\n",
    "columnas_a_eliminar = [\"app_name\", \"url\", \"tags\", \"reviews_url\", \"specs\", \"developer\", \"publisher\", \"early_access\"]\n",
    "#Eliminamos las columnas seleccionadas\n",
    "steam_games.drop(columns=columnas_a_eliminar, inplace=True)\n",
    "\n",
    "#Eliminamos las filas que tengan muchos datos nulos\n",
    "steam_games = steam_games.dropna(thresh=4)\n",
    "\n",
    "#Eliminamos los duplicados\n",
    "steam_games.drop_duplicates(subset=\"id\", inplace=True)\n",
    "\n",
    "#Cambiamos la columna a tipo numero y los valores que sean letras que los ponga como nulos y los reemplazamos por 0\n",
    "steam_games[\"price\"] = pd.to_numeric(steam_games[\"price\"], errors='coerce')\n",
    "steam_games[\"price\"] = steam_games[\"price\"].fillna(0)\n",
    "\n",
    "#Reemplazar los valores NaN por 0 para cambiar la columna a INT\n",
    "steam_games[\"id\"] = steam_games[\"id\"].fillna(0)\n",
    "#Cambio la columna a INT\n",
    "steam_games[\"id\"] = steam_games[\"id\"].astype(int)\n",
    "\n",
    "#Descomprimir la columna de genero(\"genres\")\n",
    "#Pasamos la columna de tipo objeto a tipo lista para poder usar el explode\n",
    "from ast import literal_eval\n",
    "\n",
    "def convertir_a_lista(cadena):\n",
    "    try:\n",
    "        return literal_eval(cadena)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None  # Manejar el caso en el que la cadena no sea una lista válida\n",
    "\n",
    "# Aplicar la función a la columna\n",
    "steam_games[\"genres\"] = steam_games[\"genres\"].apply(convertir_a_lista)\n",
    "#Aplicar el explode para descomprimir la lista\n",
    "steam_games = steam_games.explode(\"genres\")\n",
    "\n",
    "#Reseteamos los indices\n",
    "steam_games.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Cambiamos la columna release date a tipo datetime\n",
    "steam_games[\"release_date\"] = pd.to_datetime(steam_games[\"release_date\"],errors='coerce')\n",
    "\n",
    "#Creamos una columna especifica para el año\n",
    "steam_games[\"año\"] = steam_games[\"release_date\"].dt.year\n",
    "#Usamos interpolacion linear para llenar los nulos de los años\n",
    "steam_games[\"año\"].interpolate(method='ffill', inplace=True)\n",
    "#Pasamos la columna a tipo int\n",
    "steam_games[\"año\"] = steam_games[\"año\"].astype(int)\n",
    "\n",
    "#Eliminamos la columna release_date porque no la vamos a usar ya que tenemos el año\n",
    "steam_games.drop(columns=\"release_date\", inplace=True)\n",
    "\n",
    "#Guardamos el csv limpio:\n",
    "steam_games.to_csv(\"Csv_limpios/steam_games_limpio.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo User Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza de user items\n",
    "#Eliminamos las columnas innecesarias\n",
    "items = items.drop(columns=[\"user_url\", \"steam_id\"])\n",
    "\n",
    "# Aplicar la función que creamos antes para pasar la columna de objeto a lista y aplicar el pd.explode\n",
    "items[\"items\"] = items[\"items\"].apply(convertir_a_lista)\n",
    "#Aplicamos el explode\n",
    "items = items.explode(\"items\")\n",
    "\n",
    "#Descomprimimos el diccionario de items en otro dataframe\n",
    "items_inventario = pd.json_normalize(items[\"items\"])\n",
    "\n",
    "#Reseteamos los indices\n",
    "items_inventario.reset_index(drop=True, inplace=True)\n",
    "items.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Juntamos los dataframes\n",
    "items_final = items.join(items_inventario)\n",
    "\n",
    "#Eliminamos la columna items que contiene el diccionario y no lo necesitamos\n",
    "items_final.drop(columns=\"items\", inplace=True)\n",
    "\n",
    "#Cambiamos el tipo de dato de la columna de item id a INT\n",
    "items_final[\"item_id\"] = items_final[\"item_id\"].fillna(0)\n",
    "items_final[\"item_id\"] = items_final[\"item_id\"].astype(int)\n",
    "\n",
    "#Guardamos el csv\n",
    "items_final.to_csv(\"Csv_limpios/steam_items_limpio.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo User Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"datasets/australian_user_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza de reviews\n",
    "#Eliminamos las columnas innecesarias\n",
    "reviews = reviews.drop(columns=\"user_url\")\n",
    "\n",
    "#Eliminamos los duplicados\n",
    "reviews.drop_duplicates(inplace=True)\n",
    "\n",
    "# Aplicar la función que creamos antes para pasar la columna de objeto a lista y aplicar el pd.explode\n",
    "reviews['reviews'] = reviews['reviews'].apply(convertir_a_lista)\n",
    "#Aplicamos el explode\n",
    "reviews = reviews.explode(\"reviews\")\n",
    "\n",
    "#Descomponemos el diccionario de la columna reviews\n",
    "reviews_descomprimido = pd.json_normalize(reviews[\"reviews\"])\n",
    "\n",
    "#Eliminamos las columnas innecesarias\n",
    "columnas = [\"funny\", \"last_edited\", \"helpful\"]\n",
    "reviews_descomprimido.drop(columns=columnas, inplace=True)\n",
    "\n",
    "#Eliminamos la columna reviews del dataframe original, para luego unirlo con el archivo reviews descomprimido\n",
    "reviews.drop(columns=\"reviews\", inplace=True)\n",
    "\n",
    "#Cambiamos de la columna recommend los True por 1 y los False por 0\n",
    "reviews_descomprimido[\"recommend\"] = reviews_descomprimido[\"recommend\"].replace(True, 1)\n",
    "reviews_descomprimido[\"recommend\"] = reviews_descomprimido[\"recommend\"].replace(False, 0)\n",
    "#Cambiamos la columna a tipo entero, eliminando los datos nulos que tiene la columna recommend\n",
    "reviews_descomprimido.dropna(subset=[\"recommend\"], inplace=True)\n",
    "reviews_descomprimido[\"recommend\"] = pd.to_numeric(reviews_descomprimido[\"recommend\"], errors=\"coerce\").astype(int)\n",
    "\n",
    "#A reviews descomprimido le cambiamos el formato de la fecha:\n",
    "reviews_descomprimido[\"posted\"] = pd.to_datetime(reviews_descomprimido[\"posted\"].astype(str).str.replace(r'Posted |,|\\.', '', regex=True), errors='coerce')\n",
    "\n",
    "#Usamos interpolacion linear para llenar los nulos de los años\n",
    "reviews_descomprimido['posted'].interpolate(method='ffill', inplace=True)\n",
    "\n",
    "#Creamos una columna especifica para el año:\n",
    "reviews_descomprimido[\"year\"] = reviews_descomprimido[\"posted\"].dt.year.astype(int)\n",
    "\n",
    "#Cambiamos la columna item_id a int\n",
    "reviews_descomprimido[\"item_id\"] = reviews_descomprimido[\"item_id\"].astype(int)\n",
    "\n",
    "#Eliminamos la columna posted ya que no la vamos a usar porque solo necesitamos el año\n",
    "reviews_descomprimido.drop(columns=\"posted\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de NLP para crear la columna de sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos la columna a tipo string\n",
    "reviews_descomprimido[\"review\"] = reviews_descomprimido[\"review\"].astype(str)\n",
    "#A la columna de review le tenemos que sacar los signos de puntuacion y poner todo en minusculas para que el modelo\n",
    "#Pueda funcionar de manera correcta\n",
    "reviews_descomprimido[\"review\"] = reviews_descomprimido[\"review\"].str.lower()\n",
    "reviews_descomprimido[\"review\"] = reviews_descomprimido[\"review\"].apply(lambda x: ''.join(char for char in x if char not in string.punctuation))\n",
    "#Eliminamos los caracteres que no son alfabeticos\n",
    "reviews_descomprimido[\"review\"] = reviews_descomprimido[\"review\"].apply(lambda x: re.sub(\"[^a-zA-Zñíá]\", \" \", str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#importamos lo necesario\n",
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "analizador_sentimientos = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Creamos una funcion que analiza los sentimientos del texto proporcionado 0(malo), 1(neutral), 2(positivo)\n",
    "#Si es un dato nulo devuelve un 1 (neutral)\n",
    "def sentimientos(texto):\n",
    "    if pd.isnull(texto) or texto == \"\":\n",
    "        return 1  # Valor neutral si el texto está vacío o es NaN\n",
    "    elif isinstance(texto, str):\n",
    "        # Realizamos análisis de sentimiento\n",
    "        sentiment = analizador_sentimientos.polarity_scores(texto)\n",
    "        compound_score = sentiment[\"compound\"]\n",
    "        if compound_score > 0:\n",
    "            return 2 # Positivo\n",
    "        elif compound_score < -0:\n",
    "            return 0 # Negativo\n",
    "        else:\n",
    "            return 1 # Neutral\n",
    "    else:\n",
    "        return 1  # Valor neutral para datos que no son de tipo cadena\n",
    "    \n",
    "reviews_descomprimido[\"sentiment_analysis\"] = reviews_descomprimido[\"review\"].apply(sentimientos)\n",
    "\n",
    "#Eliminamos la columna de reviews porque no la vamos a necesitar\n",
    "\n",
    "reviews_descomprimido.drop(columns=\"review\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reseteamos los indices para asegurarnos poder juntar correctamente los dataframes\n",
    "reviews.reset_index(drop=True, inplace=True)\n",
    "reviews_descomprimido.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Unimos los dataframes de reviews y el de reviews_descomprimido y lo guardamos en un csv\n",
    "reviews = reviews.join(reviews_descomprimido)\n",
    "\n",
    "#Pasamos item id, recommend y sentiment analysis a entero\n",
    "reviews.dropna(subset=[\"item_id\"], inplace=True)\n",
    "reviews[\"item_id\"] = reviews[\"item_id\"].astype(int)\n",
    "reviews[\"recommend\"] = reviews[\"recommend\"].astype(int)\n",
    "reviews[\"sentiment_analysis\"] = reviews[\"sentiment_analysis\"].astype(int)\n",
    "\n",
    "#Guardamos el csv\n",
    "reviews.to_csv(\"Csv_limpios/steam_reviews_limpio.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
